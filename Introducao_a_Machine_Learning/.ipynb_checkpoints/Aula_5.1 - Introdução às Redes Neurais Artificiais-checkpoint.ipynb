{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução a Machine Learning\n",
    "\n",
    "# 5.1 - Introdução às Redes Neurais Artificiais\n",
    "\n",
    "Olá\n",
    "\n",
    "Nesta aula, daremos continuidade ao nosso curso de Machine Learning, aprendendo um pouco sobre as redes neurais. As redes neurais formavam um modelo que foi usado por vários anos. O seu primeiro registro é de 1943 com o **Modelo de McCulloch-Pitts**.\n",
    "\n",
    "![imagem.png](imagem/figura_5.1_1.png)\n",
    "\n",
    "Esse modelo era inspirado no neurônio biológico, o neurônico do corpo humano, do sistema nervoso e faz parte de um área da computação chamada **computação bioinspirada**, ou seja, inspirada na maneira que seres humanos vivem ou funcionam. \n",
    "\n",
    "Este modelo de redes reurais foi utilizado por vários anos. até o final da década de 1980 quando foram descoberta limitações que, aparentemente, não poderiam permitir que as redes neurais fossem usadas para problemas complexos. Então, as redes neurais passaram um tempo fora de uso, fora de moda dentro da área de inteligência artificial. E elas voltaram a aparecer por volta de 2006 com o surgimento do Deep Learning, ou aprendizagem profunda que foram técnicas usadas para que se voltasse a utilizar as redes neurais. Evitando as limitações que haviam sido encontradas antes. \n",
    "\n",
    "Nesta aula, iremos falar sobre como as redes neurais funcionam, a comparação delas em relação ao sistema nervoso, ao neurônio biológico e iremos formar a base deste modelo.\n",
    "\n",
    "Relembrando um pouco sobre neurônio normal, o neurônio Natural que nós humanos utilizamos sabemos que os neurônios são subdivididos em três áreas:\n",
    "* Uma delas são os **dendritos** que recebem a informação de outros neurônios ou do ambiente externo;\n",
    "* Essa informação vai para o **núcleo** do neurônio;\n",
    "* Uma vez que essa informação que vem do ambiente externo ou de outros neurônios, for o suficiente para se captada, essa informação é enviada por meio de sinais elétricos. Uma vez que certa voltagem é alcançada, a somatório dos impulsos elétricos que chegam nesse neurônio passa de um certo valor, de um certo limiar,  nós podemos dizer que esse **neurônio é ativado** ou que entramos na fase de excitação do neurônio. Quando isso ocorre, toda a energia que recebeu, ele passará adiante. Ele vai ser ativado, e vai passar adiante a sua energia por meiro do **axônio**, que seria o corpo do neurônio. E vai entregar essa energia para a sinapse que é onde a energia será transmitida para os próximos neurônios do nosso sistema nervoso.\n",
    "\n",
    "Basicamente, o neurônio tem esse funcionamento: ele vai receber uma carga elétrica, e se essa carga elétrica recebida da sua vizinhança for superior a um certo limiar, esse neurônio vai ser ativado, e passará sua carga elétrica adiante até a sinapse onde ele enviará essa carga elétrica para o próximo neurônio. E, assim, a corrente elétrica vai sendo passada pelos neurônios até chegar no cérebro onde ela vai ser processada. E será retornada como um impulso para alguma parte do corpo. \n",
    "\n",
    "Então, podemos dizer que existe uma camada de entrada que recebe as informações, uma camada intermediária que processará essas informações recebida e uma camada de saída que transmite um aprendizado a partir dessas informações processadas.\n",
    "\n",
    "\n",
    "## O Neurônio Artificial\n",
    "\n",
    "\n",
    "Nessa aula iremos continuar discussão sobre as redes neurais, tentando entender um pouco como funcionar um neurônio artificial, o primeiro modelo de McCulloch-Pitts que é um modelo bem antigo, de 1943. Mas, até hoje, ele ainda é utilizado como base para rede neural, por ser simplista, refletindo, de fato a computação que ocorre no neurônio humano, no neurônio natural, além de eficaz. Ele funciona muito bem, e ele tem algumas analogias com alguns modelos que trabalhamos em outras aulas. \n",
    "\n",
    "Então, em relação ao neurônio artificial, é importante compreender o seu funcionamento para que entendamos como a rede neural funciona, como ela se comporta. Então, o neurônio artificial vai ter a seguinte característica:\n",
    "\n",
    "![imagem.png](imagem/figura_5.1_2.png)\n",
    "\n",
    "Podemos ter um conjunto de variáveis de entrada, onde cada um dessas variáveis irá levar uma informação. Cada variável tem uma informação diferente. Ou seja, é como se cada uma dessas variáveis fosse um impulson externo que podemos, também, traduzir como os nossos dados de entrada. Ou esta variável pode, também, ser o resultado da computação de um neurônio anterior. Mas, o nosso neurônio está sendo preparado dessa maneira: uma variável de entrada paraa cada sinal. Ou seja, imaginando uma função, cada variável dessa seria o parâmetro de entrada da função. E dentro desse neurônio a informaçãõ de entrda é processada. Ou seja, alguma computação é feita. E nós temos a saída desse neurônio que vai ser, por exemplo, 0 ou 1. Nesse modelo mais simples de McCulloch-Pitts.\n",
    "\n",
    "Então, nós temos várias entradas, que são parâmetros de um função, assim, imaginamos, a execução dessa função e uma saída que, no caso desse primeiro modelo criado, era 0 ou 1. E as entradas também eram de 0 ou 1. Estamos combinando, de algu modo, a informação de entrada para produzir uma saída, ouseja, neurônio ativado ou desativado. Tornando o modelo de McCulloch-Pitts uma equação matemática, nós iremos ter um somatório dos valores de entrada, dado que este somatório seja maior do que um limiar. Neste limiar, estamos utilizando 0, por exemplo. \n",
    "\n",
    "![imagem.png](imagem/figura_5.1_3.png)\n",
    "\n",
    "Então, se o somatório dos valores de entrada é maior que 0. O Nosso neurônio vai ser ativado, ou seja, o retorno será 1. Caso contrário, se for menor que 0, o nosso retorno será 0. Ou seja, o nosso neurônio é ativado ou desativado de acordo com o valor de entrada. \n",
    "\n",
    "Então, se formos observar o nosso neurônio, base da rede neural, a informação atômica, o que a gente tem de mais simples, ele possui uma características, uma computação bem simples. Ele vai, apenas, efetuar um somatório dos dados de entrada e dependendo desse vlor, retorna se esse neurônio foi ativado ou não.\n",
    "\n",
    "Existem alguns pontos interessantes nesta teoria que evoluiu um pouco utilizando a mesma base do neurônio de McCulloch-Pitts. Porém, quando fomos utilizar a rede neural foi criado o conceito de **perceptron**.\n",
    "\n",
    "O **perceptron** é bem parecido com a ideia anterior, ou seja, um somatório das entradas. Porém, existe, agora, um peso que multiplica cada uma das entradas. Ou seja, para cada uma das variáveis de entrada, nós temos, também, um peso associado a elas que é independente das demais. \n",
    "\n",
    "Supondo que temos duas variáveis, uma variável x0 e uma variável x1. Essa variável x0 v ai ter um peso w0 e a variável x1 vai ter um peso w1. Então, iremos computar sobre esses pesos, ou seja, a nossa somatória que antes era a soma da variável x0 mais a soma da variável x1. Agora, é o peso w0  vezes o x0 mais o w1 vezes o x1. \n",
    "___\n",
    "Ou seja , cada peso irá multiplicar a sua variável correspondente e teremos a soma desses produtos.\n",
    "___\n",
    "\n",
    "O perceptron tem essa característica de ter o peso. Dessa forma, podemos diferenciar a entrada, tornar um neurônio mais sensível a uma entrada e menos sensível a outra. E, assim, podemos ter uma diferenciação, uma complexidade maior na informaçao que está chegando nesse neurônio e como essa informação irá sair.\n",
    "\n",
    "Além disso, na rede neural, temos uma diferenciação que é o que chamamos de **função de ativação**. A função de ativação é o seguinte: uma vez que essa soma é calculada, somam-se os produtos de cada variável peloseu peso, essa soma final passará por uma função de ativação que seria, basicamente, uma função que transforma o valor. Essa função é linear.\n",
    "\n",
    "Temos, também, a função conhecida como \"**ReLU**\", _Rectified Linear Unit_ que apenas retifica os valores menores que 0. Ou seja, se o somatório de menor que 0, a minha função do neurônio irá retornar igual a 0. Caso contrário, se for maior que 0, ela retorna o valor correspondente.\n",
    "\n",
    "Essa rede neural é muito utilizada no reconhecimento de imagens, de reconhecimento de padrões em imagens e sons. \n",
    "\n",
    "Existem algumas funções, cada um delas tem sua utilidade, o seu propósito. E nosso modelo será o que chamos de **Multilayer Perceptron** ou o perceptron de multicamadas. Que seria extamente os neurônios conectados onde temos as variáveis de entrada que serão as entradas de cada uma das variáveis. \n",
    "\n",
    "Imagine um conjunto de dados: cada elemento da coluna dos dados irá para um neurônio de entrada que será uma variável. E aí, temos que a primeira camada dos neurônicos irá receber exatamente os calores de fora, os que estão entrando no modelo. E as camadas seguintes irão receber como entrada as suas variáveis onde serão executadas as suas computações, serão as saídas das camadas anteriores de neurônios. Dessa maneira, temos a ideia da **especialização do dado**. \n",
    "\n",
    "## O Exemplo do \"OU-EXCLUSIVO\"\n",
    "\n",
    "Nessa aula iremos falar sobre as características do \"Ou-Exclusivo\" que é uma porta lógica que existe na lógica matemática. E ela é extremamente importante, tanto para a computação quanto para a língua portuguesa, por exemplo. Ou a porta XOR como também é conhecida. É simplesmente uma operação XOR \"bit a bit\" sobre dois valores binários que indica \"1\", se e somente se um dos bits possuír valor lógico \"1\", e \"0\", se dois ou mais bits possuírem \"1\" como valor lógico, ou ainda se todos os bits possuírem \"0\" como valor lógico. \n",
    "\n",
    "![imagem.png](imagem/figura_5.1_4.png)\n",
    "\n",
    "Relembrando a tabela verdade:\n",
    "\n",
    "![imagem.png](imagem/figura_5.1_5.png)\n",
    "\n",
    "Ou exclusivo, na língua portuguesa, por exemplo, no qual pedimos para executar a compra de bana ou maça. Você não deve comprar os dois. Apenas uma das duas, exclusivamente, será satisfeita. Ou seja, não comprar nem banana nem maça não é válido tanto quanto comprar ambas as frutas. Ela só vai estar verdadeira se você comprar bana, mas não maçã, ou vice-versa.\n",
    "\n",
    "![imagem.png](imagem/figura_5.1_4.png)\n",
    "\n",
    "Se fossemos construir um gráfico onde , no eixo horizontal, nós teremos a primeira entrada da variável e no eixo vertical, teremos a outra entrada, nóstemos que a origem dessas nossas coordenadas seja igual a 0, por exemplo. Temos que os nossos dados não vão ser linearmente separáveis. \n",
    "\n",
    "Ou seja, modelo de regressão linear não conseguiria separa bem o \"ou-exclusivo\". Então, dessa maneira, precisamos de um modelo um pouco mais complexo que não trabalha apenas com uma reta. Nós precisamos de um modelo não linear. E a rede neural pode ser não linear.\n",
    "\n",
    "Então, as redes neurais funcionam dessa maneira: Nós camos construindo retas a cada neurônio e elas vão se especializando a cada camada para caracterizarem e encontrarem padrões cada vez mais complexos nos neurônios. \n",
    "\n",
    "\n",
    "## Implementando as Redes Neurais\n",
    "\n",
    "Nas aulas anteriores, aprendemos o funcionamento básico de uma rede neural, o modo como ela computar uma informação. Nessa aula, iremos aprender a implementar uma rede neural a partir da biblioteca **Scikit-learn** e alguns dos cuidados especiais que devemos ter na sua implementação.\n",
    "\n",
    "Primeiramente, iremos importar a rede neural e algumas blibliotecas que utilizaremos no decorrer dele:\n",
    "\n",
    "``\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import load_boston\n",
    "``\n",
    "\n",
    "Ainda iremos importar a função de divisão treino e teste; Iremos utilizar o MinMaxScaler para traduzir as nossas variáveis de entrada, as nossas  **features**; Também importamos o dataset de Boston, de precificação das casas de Boston, já utilizado em aulas anteriores. Pronto! Dessa maneira, nós temos os ``import`` para utilizar a rede neural. \n",
    "\n",
    "Em seguida iremos carregar o nosso conjunto de dados para as variáveis X e y. \n",
    "\n",
    "``\n",
    "X,y = load_boston(return_X_y=True)\n",
    "``\n",
    "\n",
    "Na sequência, aplicaremos a **função de divisão de treino e teste** do nosso conjunto de dados.\n",
    "\n",
    "``\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "``\n",
    "\n",
    "Agora, faremos o pré-processamento do nosso conjunto de dados ao aplicar a **função MinMaxScaler**. Essa hora, devemos ter muito cuidado para aplicar essa função em um modelo de rede neural que ele tente a se beneficiar de conjunto de dados com uma escala reduzida.\n",
    "\n",
    "``\n",
    "mm = MinMaxScaler()\n",
    "X_train = mm.fit_transform(X_train)\n",
    "X_test = mm.transform(X_test)\n",
    "``\n",
    "\n",
    "Dessa maneira, estamos transformando os dados de \"Test\" de acordo com os limites de \"train\". Então, os nossos conjuntos de dadosvão ter essa transformação do \"teste, de acordo com o \"train\". Esta é uma técnica que utilizamos, de separar essa divisão para evitar o que chamamos de **data leak**, ou seja, que as informações de \"train\" sejam vazadas para o \"test\". Ao executar essas linhas, então, os nossos dados foram  transformados em uma escala menor.\n",
    "\n",
    "``\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(100,100,50,50),max_iter=1000)\n",
    "``\n",
    "\n",
    "Onde a variável mlp recebe nossa rede neural para implementá-la. Em seguida, entre parênteses, podemos aplicar algumas funções, definir o número de camadas da nossa rede neural, o modo de ativação. Por padrão, esse modelo utiliza o ReLU para ativação. Correlação ao tamanho do nosso neurônio, vai depende do tamanho do nosso problema. Como padrão, ele vai ter apenas uma camada intermediária como chamamos, uma camada curta de 100 neurônios. \n",
    "\n",
    "O que seria essa camada curta? Nós temos a camada de entrada, os valores de entrada do problema, temos a primeira camada de neurônios que é a primeira camada curta e a camada de saída, ou seja, nosso valor de saída é só um neurônio. E ele funciona para nossa classificação e regressão. Então, o que vamos definir é o número de camadas ocultas. A saída e a entrada são definidas automaticamente. Não é necessário mexermos nelas.\n",
    "\n",
    "Assim, entre parênteses colocamos o seguinte função \"**hidden_layer_sizes**\" que significa tamanho da camadas ocultas, ou camadas intermediárias; em seguida, definimos o número de camadas e o número de cada uma dessas camadas, serparadas por vírgula. Por exemplo, ``(10, 10, 10)`` podemos dizer que temos três camadas intermediárias contendo em cada uma delas 10 neurônios. E podemos ir reajustando à medida que obtemos os resultados. \n",
    "\n",
    "Lembrando: muitas camadas e neurônios podem gerar um modelo muito complexo e podemos ter um _overfitting_ a partir disso.\n",
    "\n",
    "Em seguida, iremos treinar nosso modelo com o seguinte comando:\n",
    "\n",
    "``\n",
    "mlp.fit(X_train,y_train)\n",
    "``\n",
    "\n",
    "Na sequência, verificaremos com a **função score**:\n",
    "\n",
    "``\n",
    "mlp.score(X_test,y_test)\n",
    "\n",
    "``\n",
    "\n",
    "Podemos ir testando nossa rede neural, definindo novos tamanhos para ela e verificando com a função score, até obtemos um melhor desempenho do nosso modelo. Poderia ser a nossa quantidade máxima de interações. Então, vou adicionar um novo atributo no nosso \"MLPRegressor\", do lado do tamanho da nossa rede, ``max_iter=``, por padrão é definido 200, podemos colocar então 1000. E ao avaliar o score temos um resultado melhor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = MinMaxScaler()\n",
    "X_train = mm.fit_transform(X_train)\n",
    "X_test = mm.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPRegressor(hidden_layer_sizes=(100,100,50,50),max_iter=1000,learning_rate='adaptive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "             hidden_layer_sizes=(100, 100, 50, 50), learning_rate='adaptive',\n",
       "             learning_rate_init=0.001, max_fun=15000, max_iter=1000,\n",
       "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "             power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8325635268553215"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
